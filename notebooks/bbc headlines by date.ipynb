{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "class WebPageExtractor:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.soup = None\n",
    "        self.json_data = None\n",
    "\n",
    "    def fetch_page(self):\n",
    "        \"\"\"Fetches the web page content and initializes BeautifulSoup.\"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.url)\n",
    "            response.raise_for_status()  # Raise an HTTPError for bad responses\n",
    "            self.soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            print(\"Page fetched successfully.\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Failed to fetch page: {e}\")\n",
    "            self.soup = None\n",
    "\n",
    "    def extract_json_metadata(self):\n",
    "        \"\"\"Extracts JSON metadata from the <script> tag with type 'application/ld+json'.\"\"\"\n",
    "        if self.soup:\n",
    "            script_tag = self.soup.find('script', type='application/ld+json')\n",
    "            if script_tag:\n",
    "                try:\n",
    "                    self.json_data = json.loads(script_tag.string)\n",
    "                    print(\"JSON metadata extracted successfully.\")\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Failed to parse JSON metadata: {e}\")\n",
    "                    self.json_data = None\n",
    "            else:\n",
    "                print(\"No JSON metadata found.\")\n",
    "        else:\n",
    "            print(\"Soup object not initialized. Call fetch_page() first.\")\n",
    "\n",
    "    def extract_author(self):\n",
    "        \"\"\"Extracts author(s) from the JSON metadata.\"\"\"\n",
    "        if self.json_data:\n",
    "            author_info = self.json_data.get(\"author\", None)\n",
    "            if author_info:\n",
    "                if isinstance(author_info, list):\n",
    "                    authors = [author.get(\"name\", \"Unknown\") for author in author_info]\n",
    "                else:\n",
    "                    authors = [author_info.get(\"name\", \"Unknown\")]\n",
    "                return authors\n",
    "            else:\n",
    "                return \"No author information found.\"\n",
    "        return \"No JSON metadata found.\"\n",
    "\n",
    "    def extract_date(self):\n",
    "        \"\"\"Extracts the publication date from the JSON metadata.\"\"\"\n",
    "        if self.json_data:\n",
    "            return self.json_data.get(\"datePublished\", \"No publication date found.\")\n",
    "        return \"No JSON metadata found.\"\n",
    "\n",
    "    def extract_headline(self):\n",
    "        \"\"\"Extracts the headline from the JSON metadata.\"\"\"\n",
    "        if self.json_data:\n",
    "            return self.json_data.get(\"headline\", \"No headline found.\")\n",
    "        return \"No JSON metadata found.\"\n",
    "\n",
    "    def extract_content(self):\n",
    "        \"\"\"Extracts the article content from <p> tags.\"\"\"\n",
    "        if self.soup:\n",
    "            paragraphs = self.soup.find_all('p')\n",
    "            article_content = '\\n'.join([p.get_text(strip=True) for p in paragraphs])\n",
    "            return article_content if article_content else \"No content found.\"\n",
    "        return \"Soup object not initialized. Call fetch_page() first.\"\n",
    "\n",
    "class RSSFeedExtractor:\n",
    "    def __init__(self, rss_urls):\n",
    "        self.rss_urls = rss_urls\n",
    "        self.df = None\n",
    "\n",
    "    def get_source_name(self, url):\n",
    "        domain = urlparse(url).netloc\n",
    "        source = domain.replace('www.', '').split('.')[0]\n",
    "        return source\n",
    "\n",
    "    def parser_items_rss(self, url):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'xml')\n",
    "        items = soup.find_all('item')\n",
    "        source = self.get_source_name(url)\n",
    "\n",
    "        lista_items = []\n",
    "        for item in items:\n",
    "            row = {\n",
    "                \"title\": item.find('title').text if item.find('title') else None,\n",
    "                \"description\": item.find('description').text if item.find('description') else None,\n",
    "                \"url\": item.find('link').text if item.find('link') else None,\n",
    "                \"pubDate\": item.find('pubDate').text if item.find('pubDate') else None,\n",
    "                \"source\": source\n",
    "            }\n",
    "            lista_items.append(row)\n",
    "\n",
    "        return lista_items\n",
    "\n",
    "    def fetch_rss_feeds(self):\n",
    "        datos = []\n",
    "        for url in self.rss_urls:\n",
    "            datos.extend(self.parser_items_rss(url))\n",
    "        \n",
    "        self.df = pd.DataFrame(datos)\n",
    "        self.df = self.df.drop(['pubDate'], axis=1)\n",
    "        self.df[\"type\"] = self.df[\"url\"].str.extract(r\"https://www\\.bbc\\.com/news/([^/]+)/\")\n",
    "        self.df = self.df[self.df['type'] == 'articles']\n",
    "        return self.df\n",
    "\n",
    "class WebPageMetadataExtractor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def extract_webpage_info(self, row):\n",
    "        url = row['url']\n",
    "        extractor = WebPageExtractor(url)\n",
    "        \n",
    "        # Fetch page and extract metadata\n",
    "        try:\n",
    "            extractor.fetch_page()\n",
    "            extractor.extract_json_metadata()\n",
    "            return {\n",
    "                'Author': extractor.extract_author(),\n",
    "                'Date Published': extractor.extract_date(),\n",
    "                'Headline': extractor.extract_headline(),\n",
    "                'Content': extractor.extract_content(),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing URL {url}: {e}\")\n",
    "            return {\n",
    "                'Author': None,\n",
    "                'Date Published': None,\n",
    "                'Headline': None,\n",
    "                'Content': None,\n",
    "            }\n",
    "\n",
    "    def fetch_webpage_metadata(self):\n",
    "        # Use tqdm for progress bar during extraction\n",
    "        tqdm.pandas()\n",
    "        extracted_data = self.df.progress_apply(self.extract_webpage_info, axis=1, result_type='expand')\n",
    "        return pd.concat([self.df, extracted_data], axis=1)\n",
    "\n",
    "class FilteredArticles:\n",
    "    def __init__(self, rss_urls):\n",
    "        self.rss_extractor = RSSFeedExtractor(rss_urls)\n",
    "        self.metadata_extractor = None\n",
    "        self.df = None\n",
    "\n",
    "    def fetch_rss_articles(self):\n",
    "        # Fetch RSS feeds and parse items\n",
    "        self.df = self.rss_extractor.fetch_rss_feeds()\n",
    "        return self.df\n",
    "\n",
    "    def fetch_webpage_metadata(self):\n",
    "        # Fetch metadata for the articles fetched from RSS\n",
    "        self.metadata_extractor = WebPageMetadataExtractor(self.df)\n",
    "        self.df = self.metadata_extractor.fetch_webpage_metadata()\n",
    "        return self.df\n",
    "\n",
    "    def filter_by_date(self):\n",
    "        # Convert the \"Date Published\" column to datetime\n",
    "        self.df['Date Published'] = pd.to_datetime(self.df['Date Published'])\n",
    "\n",
    "        # Get today's date\n",
    "        today = datetime.now().date()\n",
    "\n",
    "        # Filter articles published today\n",
    "        filtered_df = self.df[self.df['Date Published'].dt.date == today]\n",
    "        return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/201 [00:00<00:15, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/201 [00:00<00:19, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/201 [00:00<00:24,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 10/201 [00:01<00:23,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/201 [00:01<00:22,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/201 [00:01<00:24,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/201 [00:01<00:22,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/201 [00:02<00:22,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 20/201 [00:02<00:21,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/201 [00:02<00:21,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/201 [00:02<00:20,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/201 [00:03<00:30,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 27/201 [00:04<01:10,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 30/201 [00:05<01:01,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/201 [00:05<00:41,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/201 [00:06<00:25,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38/201 [00:06<00:20,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/201 [00:06<00:20,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44/201 [00:07<00:18,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/201 [00:07<00:13, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/201 [00:07<00:11, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54/201 [00:07<00:10, 13.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56/201 [00:07<00:10, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 58/201 [00:08<00:12, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 63/201 [00:08<00:15,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 65/201 [00:09<00:13,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/201 [00:09<00:11, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 71/201 [00:09<00:12, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 75/201 [00:09<00:11, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 77/201 [00:10<00:10, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 79/201 [00:10<00:11, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 85/201 [00:10<00:09, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 89/201 [00:11<00:11, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 93/201 [00:11<00:10, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 96/201 [00:12<00:11,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 98/201 [00:12<00:10, 10.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 102/201 [00:12<00:09, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 106/201 [00:12<00:08, 11.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 108/201 [00:13<00:07, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 112/201 [00:13<00:08, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 114/201 [00:13<00:08, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 116/201 [00:13<00:08,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 120/201 [00:14<00:08,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 122/201 [00:14<00:07,  9.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 126/201 [00:14<00:07, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 128/201 [00:15<00:07,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 132/201 [00:15<00:06, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 134/201 [00:15<00:05, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 136/201 [00:15<00:06,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 140/201 [00:16<00:05, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 142/201 [00:16<00:05, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 146/201 [00:16<00:05, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 148/201 [00:17<00:04, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 150/201 [00:17<00:04, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 152/201 [00:17<00:05,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 156/201 [00:17<00:04, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 158/201 [00:18<00:03, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 162/201 [00:18<00:03, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 165/201 [00:18<00:04,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 167/201 [00:19<00:03,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 171/201 [00:19<00:02, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 175/201 [00:19<00:02, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 177/201 [00:20<00:02,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 181/201 [00:20<00:01, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 183/201 [00:20<00:01, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 187/201 [00:20<00:01, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 191/201 [00:21<00:00, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 193/201 [00:21<00:00, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 195/201 [00:21<00:00, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 197/201 [00:21<00:00,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 199/201 [00:22<00:00,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:22<00:00,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n",
      "Page fetched successfully.\n",
      "JSON metadata extracted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RSS feed URLs\n",
    "world_news = [\n",
    "    'https://feeds.bbci.co.uk/news/business/rss.xml?edition=uk',\n",
    "    'https://feeds.bbci.co.uk/news/education/rss.xml?edition=uk',\n",
    "    'https://feeds.bbci.co.uk/news/entertainment_and_arts/rss.xml?edition=uk',\n",
    "    'https://feeds.bbci.co.uk/news/health/rss.xml?edition=uk',\n",
    "    'https://feeds.bbci.co.uk/news/technology/rss.xml?edition=uk',\n",
    "    'https://feeds.bbci.co.uk/news/world/rss.xml?edition=uk',\n",
    "    'https://feeds.bbci.co.uk/news/science_and_environment/rss.xml?edition=uk'\n",
    "]\n",
    "\n",
    "# Create the main class instance\n",
    "filtered_articles = FilteredArticles(world_news)\n",
    "\n",
    "# Fetch RSS articles\n",
    "df_articles = filtered_articles.fetch_rss_articles()\n",
    "\n",
    "# Fetch webpage metadata\n",
    "df_metadata = filtered_articles.fetch_webpage_metadata()\n",
    "\n",
    "# Filter articles published today\n",
    "df_filtered = filtered_articles.filter_by_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `df_filtered` is your filtered DataFrame\n",
    "df_filtered = df_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date Published</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real pay rises at fastest rate since 2021</td>\n",
       "      <td>Wage growth increased by 3.4% after taking int...</td>\n",
       "      <td>https://www.bbc.com/news/articles/c4g372w32vjo</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[Michael Race]</td>\n",
       "      <td>2025-01-21 07:11:07.216000+00:00</td>\n",
       "      <td>Pay rises at fastest rate for more than three ...</td>\n",
       "      <td>Real pay in the UK has risen at its fastest ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delay to TikTok ban gets Trump sign-off</td>\n",
       "      <td>The order was among a slew of directives Trump...</td>\n",
       "      <td>https://www.bbc.com/news/articles/cd0j24rj4ryo</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[Lily Jamali and Peter Hoskins]</td>\n",
       "      <td>2025-01-21 02:12:14.130000+00:00</td>\n",
       "      <td>President Trump signs executive order delaying...</td>\n",
       "      <td>President Trump has signed an executive order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stock markets cautious as Trump signals new ta...</td>\n",
       "      <td>The US president said he is considering imposi...</td>\n",
       "      <td>https://www.bbc.com/news/articles/c1ezgdj7wvpo</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[João da Silva]</td>\n",
       "      <td>2025-01-21 00:49:46.632000+00:00</td>\n",
       "      <td>Stock markets cautious as Trump signals new ta...</td>\n",
       "      <td>Stock markets in the Asia-Pacific region made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inside Iceland's futuristic farm growing algae...</td>\n",
       "      <td>Next to a geothermal plant in Iceland a start-...</td>\n",
       "      <td>https://www.bbc.com/news/articles/c4gjry6dv4yo</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[Adrienne Murray]</td>\n",
       "      <td>2025-01-21 00:00:04.073000+00:00</td>\n",
       "      <td>Inside Iceland's futuristic farm growing algae...</td>\n",
       "      <td>In the shadow of Iceland’s largest geothermal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whitesnake guitarist John Sykes dies at 65</td>\n",
       "      <td>A statement said Sykes, who co-wrote some of t...</td>\n",
       "      <td>https://www.bbc.com/news/articles/cp8qvz0gq90o</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[Christy Cooney]</td>\n",
       "      <td>2025-01-21 04:40:41.637000+00:00</td>\n",
       "      <td>Whitesnake and Thin Lizzy guitarist John Sykes...</td>\n",
       "      <td>The British rock guitarist John Sykes, who pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>McAvoy and Lange set for Glasgow Film Festival</td>\n",
       "      <td>Now in its 21st year the festival, which start...</td>\n",
       "      <td>https://www.bbc.com/news/articles/c79d3d38pp8o</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[BBC News]</td>\n",
       "      <td>2025-01-21 06:10:29.415000+00:00</td>\n",
       "      <td>James McAvoy and Jessica Lange set for Glasgow...</td>\n",
       "      <td>X-Men star James McAvoy and double Oscar winne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yes, Minister character is government's new AI...</td>\n",
       "      <td>A new suite of AI tools for civil servants are...</td>\n",
       "      <td>https://www.bbc.com/news/articles/cy48vl3p0nyo</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[BBC News]</td>\n",
       "      <td>2025-01-21 00:05:26.507000+00:00</td>\n",
       "      <td>Yes, Minister character is government's new AI...</td>\n",
       "      <td>Government workers will soon be given access t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Extra £1.5m needed to complete Jersey Opera House</td>\n",
       "      <td>The theatre says additional funding is needed ...</td>\n",
       "      <td>https://www.bbc.com/news/articles/c1dgre230r3o</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[Elliot Ball]</td>\n",
       "      <td>2025-01-21 06:08:17.025000+00:00</td>\n",
       "      <td>Extra £1.5m needed to complete Jersey Opera House</td>\n",
       "      <td>The Jersey Opera House has warned it must find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Delay to TikTok ban gets Trump sign-off</td>\n",
       "      <td>The order was among a slew of directives Trump...</td>\n",
       "      <td>https://www.bbc.com/news/articles/cd0j24rj4ryo</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[Lily Jamali and Peter Hoskins]</td>\n",
       "      <td>2025-01-21 02:12:14.130000+00:00</td>\n",
       "      <td>President Trump signs executive order delaying...</td>\n",
       "      <td>President Trump has signed an executive order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yes, Minister character is government's new AI...</td>\n",
       "      <td>A new suite of AI tools for civil servants are...</td>\n",
       "      <td>https://www.bbc.com/news/articles/cy48vl3p0nyo</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[BBC News]</td>\n",
       "      <td>2025-01-21 00:05:26.507000+00:00</td>\n",
       "      <td>Yes, Minister character is government's new AI...</td>\n",
       "      <td>Government workers will soon be given access t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Best of 'frenemies': Trump's relationship with...</td>\n",
       "      <td>Weak, distracted and unprepared? How prepared ...</td>\n",
       "      <td>https://www.bbc.com/news/articles/c93ll927v18o</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[Katya Adler]</td>\n",
       "      <td>2025-01-21 00:01:34.921000+00:00</td>\n",
       "      <td>Where Trump's 'frenemy' relationship with Euro...</td>\n",
       "      <td>\"It's insane! We're heading for a general elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mystery balls on Sydney beaches found to conta...</td>\n",
       "      <td>Authorities closed nine beaches on 14 January ...</td>\n",
       "      <td>https://www.bbc.com/news/articles/cpql7wdz5vyo</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[Kelly Ng]</td>\n",
       "      <td>2025-01-21 06:52:33.378000+00:00</td>\n",
       "      <td>Sydney: Mystery balls on beaches filled with t...</td>\n",
       "      <td>The mysterious balls thatforced the closure of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mozambique opposition leader open to serving i...</td>\n",
       "      <td>Venâncio Mondlane tells the BBC the conditions...</td>\n",
       "      <td>https://www.bbc.com/news/articles/c70kzkyg0ggo</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[Ian Wafula]</td>\n",
       "      <td>2025-01-21 00:39:01.089000+00:00</td>\n",
       "      <td>Mozambique's Venâncio Mondlane open to serving...</td>\n",
       "      <td>Mozambique's main opposition leader Venâncio M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Inside Iceland's futuristic farm growing algae...</td>\n",
       "      <td>Next to a geothermal plant in Iceland a start-...</td>\n",
       "      <td>https://www.bbc.com/news/articles/c4gjry6dv4yo</td>\n",
       "      <td>feeds</td>\n",
       "      <td>articles</td>\n",
       "      <td>[Adrienne Murray]</td>\n",
       "      <td>2025-01-21 00:00:04.073000+00:00</td>\n",
       "      <td>Inside Iceland's futuristic farm growing algae...</td>\n",
       "      <td>In the shadow of Iceland’s largest geothermal ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0           Real pay rises at fastest rate since 2021   \n",
       "1            Delay to TikTok ban gets Trump sign-off    \n",
       "2   Stock markets cautious as Trump signals new ta...   \n",
       "3   Inside Iceland's futuristic farm growing algae...   \n",
       "4          Whitesnake guitarist John Sykes dies at 65   \n",
       "5     McAvoy and Lange set for Glasgow Film Festival    \n",
       "6   Yes, Minister character is government's new AI...   \n",
       "7   Extra £1.5m needed to complete Jersey Opera House   \n",
       "8            Delay to TikTok ban gets Trump sign-off    \n",
       "9   Yes, Minister character is government's new AI...   \n",
       "10  Best of 'frenemies': Trump's relationship with...   \n",
       "11  Mystery balls on Sydney beaches found to conta...   \n",
       "12  Mozambique opposition leader open to serving i...   \n",
       "13  Inside Iceland's futuristic farm growing algae...   \n",
       "\n",
       "                                          description  \\\n",
       "0   Wage growth increased by 3.4% after taking int...   \n",
       "1   The order was among a slew of directives Trump...   \n",
       "2   The US president said he is considering imposi...   \n",
       "3   Next to a geothermal plant in Iceland a start-...   \n",
       "4   A statement said Sykes, who co-wrote some of t...   \n",
       "5   Now in its 21st year the festival, which start...   \n",
       "6   A new suite of AI tools for civil servants are...   \n",
       "7   The theatre says additional funding is needed ...   \n",
       "8   The order was among a slew of directives Trump...   \n",
       "9   A new suite of AI tools for civil servants are...   \n",
       "10  Weak, distracted and unprepared? How prepared ...   \n",
       "11  Authorities closed nine beaches on 14 January ...   \n",
       "12  Venâncio Mondlane tells the BBC the conditions...   \n",
       "13  Next to a geothermal plant in Iceland a start-...   \n",
       "\n",
       "                                               url source      type  \\\n",
       "0   https://www.bbc.com/news/articles/c4g372w32vjo  feeds  articles   \n",
       "1   https://www.bbc.com/news/articles/cd0j24rj4ryo  feeds  articles   \n",
       "2   https://www.bbc.com/news/articles/c1ezgdj7wvpo  feeds  articles   \n",
       "3   https://www.bbc.com/news/articles/c4gjry6dv4yo  feeds  articles   \n",
       "4   https://www.bbc.com/news/articles/cp8qvz0gq90o  feeds  articles   \n",
       "5   https://www.bbc.com/news/articles/c79d3d38pp8o  feeds  articles   \n",
       "6   https://www.bbc.com/news/articles/cy48vl3p0nyo  feeds  articles   \n",
       "7   https://www.bbc.com/news/articles/c1dgre230r3o  feeds  articles   \n",
       "8   https://www.bbc.com/news/articles/cd0j24rj4ryo  feeds  articles   \n",
       "9   https://www.bbc.com/news/articles/cy48vl3p0nyo  feeds  articles   \n",
       "10  https://www.bbc.com/news/articles/c93ll927v18o  feeds  articles   \n",
       "11  https://www.bbc.com/news/articles/cpql7wdz5vyo  feeds  articles   \n",
       "12  https://www.bbc.com/news/articles/c70kzkyg0ggo  feeds  articles   \n",
       "13  https://www.bbc.com/news/articles/c4gjry6dv4yo  feeds  articles   \n",
       "\n",
       "                             Author                   Date Published  \\\n",
       "0                    [Michael Race] 2025-01-21 07:11:07.216000+00:00   \n",
       "1   [Lily Jamali and Peter Hoskins] 2025-01-21 02:12:14.130000+00:00   \n",
       "2                   [João da Silva] 2025-01-21 00:49:46.632000+00:00   \n",
       "3                 [Adrienne Murray] 2025-01-21 00:00:04.073000+00:00   \n",
       "4                  [Christy Cooney] 2025-01-21 04:40:41.637000+00:00   \n",
       "5                        [BBC News] 2025-01-21 06:10:29.415000+00:00   \n",
       "6                        [BBC News] 2025-01-21 00:05:26.507000+00:00   \n",
       "7                     [Elliot Ball] 2025-01-21 06:08:17.025000+00:00   \n",
       "8   [Lily Jamali and Peter Hoskins] 2025-01-21 02:12:14.130000+00:00   \n",
       "9                        [BBC News] 2025-01-21 00:05:26.507000+00:00   \n",
       "10                    [Katya Adler] 2025-01-21 00:01:34.921000+00:00   \n",
       "11                       [Kelly Ng] 2025-01-21 06:52:33.378000+00:00   \n",
       "12                     [Ian Wafula] 2025-01-21 00:39:01.089000+00:00   \n",
       "13                [Adrienne Murray] 2025-01-21 00:00:04.073000+00:00   \n",
       "\n",
       "                                             Headline  \\\n",
       "0   Pay rises at fastest rate for more than three ...   \n",
       "1   President Trump signs executive order delaying...   \n",
       "2   Stock markets cautious as Trump signals new ta...   \n",
       "3   Inside Iceland's futuristic farm growing algae...   \n",
       "4   Whitesnake and Thin Lizzy guitarist John Sykes...   \n",
       "5   James McAvoy and Jessica Lange set for Glasgow...   \n",
       "6   Yes, Minister character is government's new AI...   \n",
       "7   Extra £1.5m needed to complete Jersey Opera House   \n",
       "8   President Trump signs executive order delaying...   \n",
       "9   Yes, Minister character is government's new AI...   \n",
       "10  Where Trump's 'frenemy' relationship with Euro...   \n",
       "11  Sydney: Mystery balls on beaches filled with t...   \n",
       "12  Mozambique's Venâncio Mondlane open to serving...   \n",
       "13  Inside Iceland's futuristic farm growing algae...   \n",
       "\n",
       "                                              Content  \n",
       "0   Real pay in the UK has risen at its fastest ra...  \n",
       "1   President Trump has signed an executive order ...  \n",
       "2   Stock markets in the Asia-Pacific region made ...  \n",
       "3   In the shadow of Iceland’s largest geothermal ...  \n",
       "4   The British rock guitarist John Sykes, who pla...  \n",
       "5   X-Men star James McAvoy and double Oscar winne...  \n",
       "6   Government workers will soon be given access t...  \n",
       "7   The Jersey Opera House has warned it must find...  \n",
       "8   President Trump has signed an executive order ...  \n",
       "9   Government workers will soon be given access t...  \n",
       "10  \"It's insane! We're heading for a general elec...  \n",
       "11  The mysterious balls thatforced the closure of...  \n",
       "12  Mozambique's main opposition leader Venâncio M...  \n",
       "13  In the shadow of Iceland’s largest geothermal ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
